MapReduce

一、流程
1.split阶段
    接到hdfs文件输入，在mapreduce中的map task开始之前，将文件按照指定大小切割成若干部分，每一部分称为一个split，默认split和block大小相等，均为128M。
2.map阶段
    map的输出结果先写到内存中的环形缓冲区，每个maptask会有一个内存缓冲区，大小为100M，当达到80M时，需要将缓冲区中的数据以一个临时文件的方式存储到磁盘，
    当整个task结束后再对磁盘中这个task所产生的所有临时文件做合并，生成最终的输出文件。如果map task的结果不大，能完全存储到内存缓冲区，且未达到内存缓冲
    区的阈值，就不会有写临时文件到磁盘的操作，也不会有后面的合并。在写入的过程中会进行分区、排序、combine操作。
        *环形缓冲区：使用指针机制把内存中的地址首尾相接形成一个存储中间数据的缓冲区阈，默认100M；80M阈值，20M缓冲区，为了解决写入环形缓冲区数据的速度大于
        写出到spill文件的速度使数据丢失；Spill文件:spill文件是环形缓冲区到达阈值后写入到磁盘的单个文件，这些文件在map阶段计算结束时，会合成分好区的一个
        merge文件供给给reduce任务抓取；spill文件过小时，就不会浪费io资源合并merge；默认情况下3个以下spill文件不合并；对于在环形缓冲区中的数据，最终达
        不到80M但是数据已经计算完毕的情况，map任务将会调用flush将缓冲区中的数据强行写出spill文件。
3.shuffle阶段
    shuffle过程是MapReduce的核心，描述着数据从map task输出到reduce task输入的这段过程。reducetask是根据自己的分区号，去各个maptask分区机器上取相应
    的结果分区数据，reducetask将这些文件再进行合并。
4.reduce阶段
    抓取，合并，排序
    (1)reduce任务会创建并行的抓取线程（fetcher）负责从完成的map任务中获取结果文件，是否完成是通过rpc心跳监听，通过http协议抓取；默认是5个抓取线程，可调。
    (2)抓取过来的数据会先保存在内存中，如果内存过大也溢出，不可见，不可调，但是单位是每个merge文件，不会切分数据；每个merge文件会被封装成一个segment的对象，
    控制这个文件的读取记录操作，有两种情况出现：在内存中有merge数据，在溢写之后存到磁盘上的数据。通过构造函数来进行区分，分别创建对应的segment对象。
    (3)segment对象会放到一个内存队列中（MergerQueue）对内存和磁盘上的数据进行合并，内存中的merge对应的segment直接合并，磁盘中的合并与一个叫做合并因子的
    factor有关（默认是10）
    (4)MergerQueue继承轮换排序的接口，每个segment是排好序的，而且按照key的值大小逻辑；每个segment的第一个key都是逻辑最小的，所有的segment是按照第一个
    key大小排序的，最小的在前面，总能保证第一个segment的第一个key值是所有key的逻辑最小文件合并之后，最终交给reduce计算的是MergeQueue队列，每次计算的提取
    数据逻辑都是提取第一个segment的第一个key和value数据，一旦segment被调用了提取key的方法，mergeQueue队列将会整体重新按照最小key对segmtn排序，最终形成
    整体有序的计算结果。