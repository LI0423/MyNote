MapReduce
学习链接：  https://hadoop.apache.org/docs/r1.0.4/cn/mapred_tutorial.html#%E6%BA%90%E4%BB%A3%E7%A0%81

一、概述
        MapReduce是一个使用简易的软件框架，基于它写出来的应用程序能运行在大型集群上并以一种可靠容错的方式并行处理T级别的数据集。一个MapReduce作业通常
    会把输入的数据集切分为若干独立的数据块。由map任务以并行的方式处理它们。框架会对map的输出先进行排序，然后把结果输入给reduce任务。通常MapReduce框架
    由一个单独的master JobTracker和每个集群节点一个slave TaskTracker共同组成。master负责调度构成一个作业的所有任务，这些任务分布在不同的slave上，
    master监控执行，重新执行已经失败的任务，slave负责执行。应用程序至少应该指明输入、输出的位置，并通过实现合适的接口或抽象类提供map和reduce函数。
二、流程
1.split阶段
    接到hdfs文件输入，在mapreduce中的map task开始之前，将文件按照指定大小切割成若干部分，每一部分称为一个split，默认split和block大小相等，均为128M。
2.map阶段
    map的输出结果先写到内存中的环形缓冲区，每个maptask会有一个内存缓冲区，大小为100M，当达到80M时，需要将缓冲区中的数据以一个临时文件的方式存储到磁盘，
    当整个task结束后再对磁盘中这个task所产生的所有临时文件做合并，生成最终的输出文件。如果map task的结果不大，能完全存储到内存缓冲区，且未达到内存缓冲
    区的阈值，就不会有写临时文件到磁盘的操作，也不会有后面的合并。在写入的过程中会进行分区、排序、combine操作。
        *环形缓冲区：使用指针机制把内存中的地址首尾相接形成一个存储中间数据的缓冲区阈，默认100M；80M阈值，20M缓冲区，为了解决写入环形缓冲区数据的速度大于
        写出到spill文件的速度使数据丢失；Spill文件:spill文件是环形缓冲区到达阈值后写入到磁盘的单个文件，这些文件在map阶段计算结束时，会合成分好区的一个
        merge文件供给给reduce任务抓取；spill文件过小时，就不会浪费io资源合并merge；默认情况下3个以下spill文件不合并；对于在环形缓冲区中的数据，最终达
        不到80M但是数据已经计算完毕的情况，map任务将会调用flush将缓冲区中的数据强行写出spill文件。
3.shuffle阶段
    shuffle过程是MapReduce的核心，描述着数据从map task输出到reduce task输入的这段过程。reducetask是根据自己的分区号，去各个maptask分区机器上取相应
    的结果分区数据，reducetask将这些文件再进行合并。
4.reduce阶段
    抓取，合并，排序
    (1)reduce任务会创建并行的抓取线程（fetcher）负责从完成的map任务中获取结果文件，是否完成是通过rpc心跳监听，通过http协议抓取；默认是5个抓取线程，可调。
    (2)抓取过来的数据会先保存在内存中，如果内存过大也溢出，不可见，不可调，但是单位是每个merge文件，不会切分数据；每个merge文件会被封装成一个segment的对象，
    控制这个文件的读取记录操作，有两种情况出现：在内存中有merge数据，在溢写之后存到磁盘上的数据。通过构造函数来进行区分，分别创建对应的segment对象。
    (3)segment对象会放到一个内存队列中（MergerQueue）对内存和磁盘上的数据进行合并，内存中的merge对应的segment直接合并，磁盘中的合并与一个叫做合并因子的
    factor有关（默认是10）
    (4)MergerQueue继承轮换排序的接口，每个segment是排好序的，而且按照key的值大小逻辑；每个segment的第一个key都是逻辑最小的，所有的segment是按照第一个
    key大小排序的，最小的在前面，总能保证第一个segment的第一个key值是所有key的逻辑最小文件合并之后，最终交给reduce计算的是MergeQueue队列，每次计算的提取
    数据逻辑都是提取第一个segment的第一个key和value数据，一旦segment被调用了提取key的方法，mergeQueue队列将会整体重新按照最小key对segmtn排序，最终形成
    整体有序的计算结果。
三、详解
    1.Mapper
        Mapper将输入键值对（key/value pair）映射到一组中间格式的键值对集合。
        map是将输入记录集转换为中间格式记录集的独立任务。这种转换的中间格式不需要与输入记录集的类型一致，一个给定的输入键值对可以映射成0或多个输出键值对。
        MapReduce框架为每一个InputSplit产生一个map任务，而每个InputSplit是由该作业的InputFormat产生的。
        Map的数目通常是由输入数据的大小决定的，正常的并行规模是每个节点大约10到100个map，对于CPU消耗较小的map任务可以设到300个左右，由于每个任务初始化需要
        一定的时间，比较合理的情况是map执行的时间至少超过1分钟。
    2.Reducer
        reduce的数目建议是0.95 或1.75 乘以（<no. of nodes> * mapred.tasktracker.reduce.tasks.maximum）。用0.95，所有的reduce可以在maps一完成
        时就立刻启动，开始map的输出结果。用1.75速度快的节点可以在完成第一轮reduce任务后，可以开始第二轮，得到比较好的负载均衡效果。
    3.Partitioner
        用于划分键值空间，负责控制map输出结果key的分割。Key（或者一个key子集）被用于生产分区，通常使用的是Hash函数。分区的数目与一个作业的reduce任务的数目
        是一致的。它控制中间过程的key应该发送给m个reduce任务中的哪一个来进行reduce操作。
    4.Reporter
        用于MapReduce应用程序报告进度，设定应用级别的状态消息，更新Counters（计数器）的机制。
        Mapper和Reducer的实现可以利用Reporter来报告进度，或者仅是表明自己运行正常。框架可能以为这个任务超时了从而将其强行杀死，可以将配置参数mapred.task.timeout
        设置一个足够高的值来避免这种情况。
    5.OutputCollector
        用于收集Mapper或Reducer输出数据的通用机制（包括中间输出结果和作业的输出结果）。
    6.作业配置
        JobConf代表一个MapReduce作业的配置，是用户向Hadoop框架描述一个MapReduce作业如何执行的主要接口，框架会按照JobConf描述的信息忠实地去尝试完成这个
        作业。然而一些参数可能会被管理这标记为final，意味着不能被更改；一些作业的参数可以被直截了当的进行设置，而另一些参数则与框架或者作业的其他参数之间微妙
        的相互影响。通常JobConf会指明Mapper、Combiner、Partitioner、Reducer、InputFormat和OutputFormat的具体实现，JobConf还能指定一组输入文件以及
        输出文件写在哪。
    7.作业的提交与监控
        JobClient是用户提交的作业与JobTracker交互的主要接口。JobClient提供提交作业，追踪进程，访问自任务的日志记录，获得MapReduce集群状态信息等功能。
        作业提交的过程：检查作业输入输出样式细节；为作业计算InputSplit值；如果需要的话为作业的DistributedCache建立必须的统计信息；拷贝作业的jar包和配置
        文件到FileSystem上的MapReduce系统目录下；提交作业到JobTracker并且监控它的状态。
    8.作业的输入
        InputFormat为MapReduce作业描述输入的细节规范。MapReduce可以根据作业的InputFormat来检查作业输入的有效性；把输入文件切分成多个逻辑InputSplit实例，
        并把每一实例分发给一个Mapper；提供RecordReader的实现，这个RecordReader从逻辑InputSplit中获得输入记录，这些记录将由Mapper处理。
        InputSplit是一个单独的Mapper要处理的数据块，一般的InputSplit是字节样式输入，然后由RecorderReader处理并转化成记录样式。
        RecoderReader从InputSplit读入键值对，把由InputSplit提供的字节样式的输入文件转化成由Mapper处理的记录样式的文件。
    9.作业的输出
        OutputFormat 描述MapReduce作业的输出样式。MapReduce根据作业的OutputFormat来检验作业的输出，例如检查输出路径是否已经存在；提供一个RecordWriter的
        实现，用来输出作业结果，输出文件保存在FileSystem上。
        