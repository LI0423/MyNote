一、窗口函数
1.基本语法
    <窗口函数> over (partition by <用于分组的列名>
                    order by <用于排序的列名>)
    窗口函数包括专用窗口函数（rank,dense_rank,row_number等），聚合函数（sum,avg,count,max,min等）
    partition by 用来对表分组。
    order by 子句的功能是对分组后的结果进行排序，默认是升序。
    group by 分组汇总后改变了表的行数，一行只有一个类别。而partition by 和 rank 函数不会减少原表中的行数。
2.rank,dense_rank,row_number 的区别
    rank()：如果有并列情况，会占用下一个名次的位置，例如：1，1，1，4。
    dense_rank()：如果有并列的情况，不会占用下一个名次，例如：1，1，1，2。
    row_number()：会忽略并列的情况，例如：1，2，3，4。
3.聚合函数
    聚合函数用作窗口函数中，是对自身记录以及自身记录之上的所有数据进行计算。
    聚合函数作为窗口函数可以在每一行的数据里直观的看到截止到本行数据，统计数据是多少，对整体统计数据没影响。

二、SQL语法
1.WITH AS   
    也叫做子查询部分，可以定义一个SQL片段，该SQL片段会被整个SQL语句的可读性更高，也可以用在UNION ALL的不同部分，作为提供数据的部分。
    对与UNION ALL，使用WITH AS定义了一个UNION ALL语句，当该片段被调用2次以上，优化器会将该WITH AS短语所获取的数据放入一个Temp表中，
    [WITH <common_table_express> [ ,n]]
    <common_table_express>::=
            expression_name [(column_name [ ,n])]
        AS
            (CTE_query_definition)

2.SUM 和 CASE WHEN 组合使用
    sum(case when type = 1 then 1 when type = 2 then 1 ... end)
    计算某几种类型数据的总和。 

3.两个查询结果计算并转换为百分比形式
    select rate from (truncate(((select data from table where condition1 )/(select data from table where condition2))*100,2),'%') as rate

4.EXPLAIN 查询sql语句的执行计划
    explain select * from emp where name = 'Jefabc';
    （1）id：选择标识符。
        select的查询序列号，id如果相同，可以认为是一组，从上往下执行；如果是子查询，id的序号会递增，id值越大优先级越高，越先被执行。
    （2）select_type：查询中每个select子句的类型
        SIMPLE：单表查询，简单select，不使用UNION或子查询等。
        PRIMARY：子查询中最外层查询，查询中若包含任何复杂的子部分，最外层的select被标记为PRIMARY。
        DERIVED：在from查询中的子查询，结果存放在临时表中。
        SUBQUERY：在where列表中包含了子查询。
        DEPENDENT SUBQUERY：在select或where列表中包含了子查询，子查询基于外层。
        UNION：UNION中的第二个或后面的select语句。
        DEPENDENT UNION：UNION中的第二个或后面的select语句，取决于外面的查询
        UNION RESULT：UNION的结果，UNION语句中第二个select开始后面所有的select
    （3）table：数据库中表名称，显示这一行的数据是关于哪张表的
    （4）type：对表访问方式，标识MySQL在表中找到所需行的方式。最好到最坏依次是：
    system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > all
        ALL：Full Table Scan，MySQL将遍历全表以找到匹配的行。
        INDEX：Full Index Scan，遍历索引树。使用了索引但没有通过索引进行过滤，一般是使用了覆盖索引或是利用索引进行了排序分组。
        RANGE：只检索给定范围的行，使用一个索引来选择行。
        ref：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。
        eq_ref：类似ref，使用的是唯一索引，对于每个索引键值，表中只有一条记录匹配，就是多表连接中使用primary key或unique key作为关联条件。
        const：表最多有一个匹配行，const用于比较primary key或者unique索引。
        system：表仅有一行，是const类型的特例。
        NULL：MySQL在优化过程中分解语句，执行时甚至不用访问表或索引，例如从一个索引列里选取最小值可以通过单独索引查找完成。
    （5）possible_keys：指出MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上若存在索引，则该索引将被列出，但不一定被查询使用，如果没有任何索引显示为null。
        该列独立于EXPLAIN输出所示的表的次序，在possible_keys中的某些键实际上不能按生成的表次序使用。
    （6）key：显示MySQL实际决定使用的键（索引），必然包含在possible_keys中。
        如果没有选择索引，键是NULL，要想强制MySQL使用或忽视possible_keys列中的索引，在查询中使用FORCE INDEX、USE INDEX或者IGNORE INDEX。
    （7）key_len：表示索引中使用的字节数，可通过该列计算查询中使用的索引长度（显示的值为索引字段的最大可能长度，并非实际使用长度，即key_len是根据定义计算而得，
    不是通过表内检索出的）。不损失精度的情况下，长度越短越好。
    （8）ref：列与索引的比较，表示表的连接匹配条件，哪些列或常量被用于查找索引列上的值。
    （9）rows：估算出结果集行数，表示MySQL根据表统计信息及索引选用情况，估算找到所需的记录需要读取的行数。越小越好。
    （10）filtered: 返回结果的行占需要读到的行(rows列的值)的百分比。
    （11）extra：包含MySQL解决查询的详细信息。
        Using where：不用读取表中所有信息，仅通过索引仅可以获取所需数据，发生在对表的全部的请求列都是同一个索引的部分的时候，
            表示MySQL服务器将在存储引擎检索行后再进行过滤。
        Using temporary：表示MySQL需要使用临时表来存储结果集，常见于排序和分组查询。出现该值就表示sql需要优化了。
            MySQL 表关联的算法是 Nest Loop Join，是通过驱动表的结果集作为循环基础数据，然后一条一条地通过该结果集中的数据作为过滤条件到下一个表中查询数据，
            然后合并结果。EXPLAIN 结果中，第一行出现的表就是驱动表，对驱动表可以直接排序，对非驱动表（的字段排序）需要对循环查询的合并结果（临时表）进行排序。
        Using filesort：当Query中包含order by操作，而且无法利用索引完成的排序操作称为“文件排序”。
        Using join buffer：表示在获取连接条件时没有使用索引，并且需要连接缓冲区来存储中间结果。如果出现该值，应该注意根据查询的具体情况可能需要天机索引来改进。
        Impossible where：强调了where语句会导致没有符合条件的行。
        Select table optimized away：意味着仅通过使用索引，优化器可能仅从聚合函数结果中返回一行。
        
5.IFNULL(column,值) 
    如果某列的查询结果为null，可以转换成指定的数值返回。

6.查看sql的执行周期
    （1）查看profile是否开启。
        show variables like '%profiling%';
    （2）开启profiling。
        set profiling = 1;
    （3）使用profile可以查看最近的几次查询。
        show profiles;
    （4）根据Query_ID查看sql的具体执行步骤。
        show profile cpu,block io for query Query_ID;
    （5）sql的大致查询流程
            mysql客户端通过协议与mysql服务器建立连接，发送查询语句，检查缓存，如果命中直接返回结果，否则进行语句解析，也就是说在进行解析查询之前，服务器会先访问查询缓存，
        缓存中存储了select语句以及相应的查询结果集。如果查询结果已经在缓存中了，就不会进行解析、优化、执行。会直接将缓存中的结果返回给用户。
            语法解析器和预处理：首先mysql通过关键字将SQL语句进行解析，并生成一颗对应的解析树。mysql解析器使用mysql语法规则验证和解析查询；预处理根据一些mysql规则进一步
        检查解析树是否合法。
            查询优化器当解析树被认为是合法的了，并且由优化器将其转化为Explain。优化器的作用就是找到多种执行方式中最好的Explain。
    （6）SQL语句的书写顺序
        SELECT-DISTINCT-FROM-JOIN ON-WHERE-GROUP BY-HAVING-ORDER BY-LIMIT
    （7）SQL语句的真正执行顺序
        FROM-ON-JOIN-WHERE-GROUP BY-HAVING-SELECT-DISTINCT-ORDER BY-LIMIT

7.MySQL索引分类
    （1）单值索引index
    一个索引只包含单个列，一个表可以有多个单列索引。
        随表一起创建
            create table table_name(id int auto_increment,...,primary key(id),key(column_name));
        单独创建
            create index idx_colume_name on table_name(column_name);
        查看表的索引
            show index from 表名
            show keys from 表名
    （2）唯一索引
    索引列的值必须唯一，但允许有空值。
        随表一起创建
            unique(column_name)
        单独创建
            create unique index idx_colume_name on table_name(column_name);
    （3）主键索引
    设定为主键后数据库会自动建立索引，innodb为聚簇索引。
        删除主键索引
            alter table table_name drop primary key;
    （4）复合索引
    一个索引包含多个列
        随表一起建索引
            key(column_name1,column_name2)
        单独创建
            create index idx_name on table_name(column_name1,column_name2);

三、MySQL索引
    索引是在存储引擎层实现的，而不是在服务器层实现的。
1、B+树
    B+树是一棵平衡二叉树，主索引的叶子节点冗余了完整的数据记录，叶子节点之间还是用指针相关联起来的，查找的时候在根节点进行二分查找，找到一个key所在的
    指针，然后在指针所指向的节点进行查找，直到查找到叶子节点，然后在叶子节点上进行二分查找，找出key所对应的data。插入和删除操作会破坏平衡树的平衡性，
    在插入删除操作之后需要对树进行分裂、合并、旋转等操作。
2、哈希索引
    哈希索引能以O（1）的时间复杂度进行查找，但是失去了有序性，并且无法进行排序与分组和范围查询，只能进行精确查找。
    InnoDB存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在B+Tree索引之上再创建一个哈希索引，这样就让B+Tree索引具有
    哈希索引的一些优点，比如快速的哈希查找。
3、全文索引
    MYISAM存储引擎支持全文索引，用于查找文本中的关键词，而不是直接比较是否相等，查找条件使用MATCH AGAINST，而不是普通的WHERE。
4、空间存储索引
    MYISAM存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有纬度来索引数据，可以有效地使用任意维度来进行组合查询。
5、索引优缺点
（1）优点：
    提高数据检索的效率，降低数据库的IO成本。
    通过索引列对数据进行排序，降低数据排序的成本，降低了CPU的消耗。
（2）缺点：
    虽然索引提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE、DELETE。更新表时，Mysql不仅要保存数据，还要保存一下索引文件每次更新
    添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。
6.B-树索引
    如果要查找数据项29，首先会把磁盘块1由磁盘加载到内存，此时发生一次IO，在内存中用二分查找确定29在17和35之间，锁定磁盘块1的P2指针，通过磁盘1的P2指针
    的磁盘地址把磁盘块3由磁盘加载到内存，发生第二次IO，29在26和30之间，锁定磁盘块3的P2指针，通过加载磁盘块8到内存，发生第三次IO，同时做二分查找找到20。
7.B-Tree与B+Tree的区别
（1）B-树的关键字和记录放在一起，B+树的非叶子结点中只有关键字和指向下一个节点的索引，记录只放在叶子节点中。
（2）在B-树中，越靠近根节点的记录查找时间越快，只要找到关键字即可确定记录的存在；而B+树中每个记录的查找时间基本是一样的，都需要从根节点走到叶子节点，
而且在叶子节点中还要再比较关键字。因为B+树的非叶子结点不存放实际的数据，这样每个节点可容纳的元素个数比B-树多，树高比B-树小，减少了磁盘访问次数。尽管
B+树找到一个记录所需的比较次数比B-树多，但是一次磁盘访问的时间相当于成百上千次的内存比较时间。B+树的叶子节点使用指针连接在一起，方便顺序遍历。
（3）B+树内节点不存储数据，所有data存储在叶节点导致查询时间复杂度固定为O(logn)，而B树每个节点都有key和data，查询时间复杂度不固定，与key在树中的位置有关，最好为O(1)。
（4）B+树节点两两相连，而且在磁盘里是顺序存储的，当读到某个值的时候，磁盘预读原理会提前把这些数据读进内存，可大大增加区间访问性，可使用在范围查询等，而B树每个节点key和data
    在一起，无法区间查找。（空间局部性原理：如果一个存储器的某个位置被访问，那么它附近的位置也会被访问。）
（5）B+树更适合外部存储。由于节点内无data域，每个节点能索引的范围更大更精确。
    由于B树的节点内部每个key都带有data，而B+树只存key的副本，真实的key和data都存在叶子结点上。磁盘是分block的，一次磁盘IO会读取若干个block，磁盘IO的大小是固定的，在
    一次IO中，单个元素越小，量就越大。也就是B+树单次IO的信息量大于B树，能读出的索引值更多。

四、InnoDB的MVCC实现机制
    MVCC是为了实现读-写冲突不加锁，读指的是快照读而不是当前读，当前读是一种加锁的操作，是悲观锁的实现。
    读-读：不存在任何问题，也不需要并发控制。
    读-写：有线程安全问题，可能会造成事务隔离性问题，可能遇到脏读，幻读，不可重复度。
    写-写：有线程安全问题，可能会存在更新丢失问题，比如第一类更新丢失（回滚丢失），第二类更新丢失（覆盖丢失）。
            回滚丢失：A事务撤销时，把已经提交的B事务的更新数据覆盖了。
            覆盖丢失：A事务覆盖B事务已经提交的数据，造成B事务所做操作丢失。
1、什么是MVCC
    多版本并发控制，是一种并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。MVCC在InnoDB中的实现主要是为了提高
    数据库并发性能，用更好的方式去处理读-写冲突，做到即使有读写冲突时，也能做到不加锁，非阻塞并发读。
    MVCC只在RC和RR两个隔离级别下工作，其他两个隔离级别和MVCC不兼容，因为RU总是读取最新的数据行，而不是符合当前事务版本的数据行，而SERIALIZABLE则会对所有读取的行都加锁。

2、当前读和并发读
（1）当前读
    当前读就是像select lock in share mode(共享锁)，select * from db for update；update，insert，delete（排他锁），读取的是记录的最新版本，读取时还要
    保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。
（2）快照读
    快照读就是像不加锁的select操作就是快照读，即不加锁的非阻塞读，快照读的前提是隔离级别不是串行级别，串行级别下的快照读会退化成当前读；快照读的实现是
    基于多版本并发控制，即MVCC，可以认为MVCC是行锁的一个变种，在很多情况下，避免了加锁操作，降低了开销；既然是基于多版本，那可能读到的不一定是最新的
    版本，有可能是之前的历史版本。

3、MVCC的实现原理
    主要是依赖记录中的3个隐式字段，undo log，Read View来实现的。
（1）隐式字段
    DB_ROW_ID 6byte，隐含的自增ID（隐藏主键），如果数据表没有主键，InnoDB会自动以DB_ROW_ID产生一个聚簇索引。 
    DB_TRX_ID 6byte，最近修改（修改/插入）事务ID：记录创建这条记录/最后一次修改该记录的事务ID，每处理一个事务其值自动+1。
    DB_ROLL_PTR 7byte，回滚指针，指向这条记录的上一个版本（存储于rollback segment里）。配合undo日志，指向上一个版本。
    DELETE_BIT 1byte，记录被更新或删除并不代表真的删除，而是删除flag变了。
（2）undo log
    主要用于记录数据被修改之前的日志，在表信息修改之前会先把数据拷贝到undo log里，当事务进行回滚时可以通过undo log里的日志进行还原。
    InnoDB把这些为了回滚而记录的这些东西称之为undo log。这里需要注意的一点是，由于查询操作（SELECT）并不会修改任何用户记录，所以在查询操作时，不会记录
    用户相应的日志。undo log主要记录的是数据的逻辑变化，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，
    当update一条记录时，它记录一条对应相反的update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。

    Insert undo log：插入一条记录时，至少要把这条记录的主键值记下来，之后回滚的时候只需要把这个主键对应的记录删掉就好。
    Update undo log：修改一条记录时，至少要把修改这条记录前的旧值都记录下来，这样之后回滚时再把这条记录更新为旧值就好了。
    Delete undo log：删除一条记录时，至少要把这条记录中的内容都记下来，之后回滚时再把由这些内容组成的记录插入到表中。
        删除操作都只是设置一下老记录的DELETE_BIT，并不真正将过时的记录删除。
        InnoDB有专门的purge线程来清理DELETED_BIT为true的记录。为了不影响MVCC的正常工作，purge线程自己维护了一个read view（这个read view相当于
        系统中最老活跃事务的read view）；如果某个记录的DELETED_BIT为true，并且DB_TRX_ID相对于purge线程的read view可见，那么这条记录一定是可以
        被安全清除的。
    不同事务或者相同事务的对同一记录的修改，会导致该记录的undo log成为一条记录版本线性表，即链表，undo log的首链就是最新的旧记录，链尾就是最早的旧记录。
（3）Read View（读视图）
        主要就是有个列表来存储我们系统中当前活跃着的读写事务，也就是begin了还未提交的事务。通过这个列表来判断记录的某个版本是否对当前事务可见。这个ReadView 
    中有个 id 列表 trx_ids 来存储系统中当前活跃着的读写事务，也就是 begin 了还未 commit 或 rollback 的事务。
        RC每次查询数据前都生成一个ReadView。RR在第一次查询数据时生成一个ReadView，之后的读都复用之前的。
        readview主要是用来做可见性判断的，即当我们某个事务执行快照读的时候，对该记录创建一个readview读视图，把它比作条件用来判断当前事务能够看到哪个版本的
    数据，既可能是当前最新的数据，也可能是该行记录的undo log里面的某个版本的数据。
        readview遵循一个可见性算法，主要是将要被修改的数据的最新记录中的DB_TRX_ID（即当前事务ID）取出来，与系统当前其他活跃事务的ID去对比（由read view维护），
    如果DB_TRX_ID跟readview的属性做了某些比较，不符合可见性，那就通过DB_ROLL_PTR回滚指针去取出undo log中的DB_TRX_ID再比较，即遍历链表的DB_TRX_ID，
    直到找到满足特定条件的DB_TRX_ID，这个所在的旧记录就是当前事务能看见的最新老版本。

4、基于ReadView实现可重复读
    事务A第一次读完，事务B要修改这行数据，undolog会为所有写操作生成日志，所以就会生成一条undo log日志，roll_pointer会指向上一条undo log日志。第一次读
    的时候，开启事务A的时候就生成一个ReadView，当事务A第二次去读这条数据时，先查到的是事务B修改的那条数据，会发现现在的 DB_TRX_ID 比最小的事务ID大，有
    可能是读不到的，回去当前活跃事务列表查询是否有这条事务记录，如果有那说明在事务A开启事务的时候，这个事务是没有提交的，修改的数据就不应该被读到，顺着回滚
    指针往下找，找到之前的一条记录，发现可以读到，数值与第一次结果一致。

五、一条SQL的执行过程
    首先执行器根据MySQL的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中，在数据被缓存到缓存池的同时，
    会写入undo log日志文件。更新的动作是在BufferPool中完成的，同时会将更新后的数据添加到redo log buffer中。完成以后就可以提交事务，在提交的同时会做以下
    三件事：将redo log buffer中的数据刷入到redo log文件中；将本次操作记录写入到bin log文件中；将bin log文件名字和更新内容在bin log中的位置记录到redo
    log中，同时在redo log最后添加commit 标记。
    
六、MySQL宕机时数据不丢失的原理
    MySQL在更新数据时，为了减少磁盘的随机IO，因此并不会直接更新磁盘上的数据，而是先更新Buffer Pool中缓存页的数据，等到合适的时间点，再将这个缓存页持久化到磁盘。
    而Buffer Pool中所有缓存都是处于内存当中的，当MySQL宕机或者机器断电，内存中的数据就会丢失。当进行增删操作时，MySQL会在更新Buffer Pool中的缓存页数据时，
    会记录一条对应操作的redo log日志，当出现宕机或者断电时，如果有缓存页的数据还没来得急刷入磁盘，当MySQL重新启动时，可以根据redo log日志文件进行数据重做，
    将数据恢复到宕机或者断电前的状态，保证了更新的数据不丢失，因此redolog叫做重做日志，本质是保证事务提交后更新的数据不丢失。
    redo log中记录的是对物理磁盘上某个表空间的某个数据页的某一行数据的某个字段做的修改，修改后的值是多少。redolog日志文件是持久化在磁盘上的，磁盘上可以有多个
    redo log 文件，默认有两个文件，每个文件大小为48MB。
1、如何保证数据不丢失
（1）Mysql Server层的执行器调用InnoDB存储引擎的数据更新接口；
（2）存储引擎更新Buffer Pool中的缓存页；
（3）同时存储引擎记录一条redo log到redo log buffer中，并将该条redo log的状态标记为prepare状态；
（4）接着存储引擎告诉执行器，可以提交事务了，执行器接到通知后会写binlog日志，然后提交事务；
（5）存储引擎接到提交事务的通知后，将redo log的日志状态标记为commit状态；
（6）接着根据innodb_flush_log_at_commit参数的配置，决定是否将redo log buffer中的日志刷入磁盘。

2、两阶段事务提交
    将redolog 日志标记为prepare和commit状态，这种就是两阶段事务提交。redolog在进行重做的时候，只有读到了commit标识，才会认为这条redo log日志是完整的，
    才会进行数据重做，否则会认为这条redo log日志不完整，不会进行数据重做。

七、BinLog日志
    binlog日志是记录所有数据库表结构变更以及表数据修改的二进制日志文件，不会记录select和show这类操作。
    是mysql服务层产生的日志，常用来进行数据恢复、数据库复制，常见的mysql主从架构就是采用slave同步master的binlog实现的，另外通过解析binlog能够实现mysql到其他数据源（ES）的数据复制。
1、使用场景
（1）主从复制：在主库中开启Binlog功能，主库可以把Binlog传递给从库，从库拿到Binlog后实现数据恢复达到主从数据一致性。
（2）数据恢复：通过mysql binlog工具来恢复数据。

2、文件记录模式
（1）Row
    日志记录每一行数据被修改的情况，然后在slave端对相同数据进行修改。
    优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。
    缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨。
（2）Statement
    每一条被修改数据的SQL都会记录到master的Binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。
    优点：日志量小，减少磁盘IO，提升存储和恢复速度。
    缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。
（3）Mixed
    以上两种模式的混合使用，一般会使用Statement模式保存binlog，对于statement模式无法复制的操作使用row模式保存binlog，mysql会根据执行的sql语句选择写入模式。

3、Binlog写入机制
    常见的log event有：Query event、Row event、Xid event等。binlog 文件的内容就是各种Log event的集合。
    在事务执行过程中，先把日志写到binlog cache，事务提交的时候再把binlog cache写到binlog文件中。
    binlog cache在每个线程内空间独立的，如果启用了binlog日志，mysql会为每个session分配一个二进制日志缓存，如果经常使用大型事务，则可以增加此缓存大小来获得更好的性能，可以通过
    binlog_cache_size配置其大小，默认为32768bytes。如果binlog cache空间足够，在事务提交的时候，cache中的内容会被清空，同时这些数据会被写入到binlog files中。因为binlog
    内容无论多大在事务提交时都需要一次性写入，所以当binlog cache放不下的时候，就需要暂存到磁盘，然后提交被写入到binlog files。
    写入到binlog中又拆分为两部分：
        write：首先会写入page cache中的binlog files中，page cache就是一块内存。（不占用磁盘IOPS）
        fsync：然后操作系统执行fsync时binlog才会从page cache中真正持久化到磁盘。（占用磁盘IOPS）
    write和fsync时机：
        sync_binlog=0：表示innodb不会主动控制将binlog落盘，innodb仅仅会将binlog写入到page cache中，至于什么时间将binlog刷入磁盘中完全依赖于操作系统，选这种策略，一旦操作系统宕机，
        page cache中的binlog就会丢失。每次提交事务只是write，不执行fsync，也就是binlog不做持久化。
        sync_binlog=1：表示事务commit时将binlog落盘，哪怕机器宕机了也能确保binlog会被写入到磁盘中。每次提交事务都要发生fsync。
        sync_binlog=N：表示每次事务都会write，但是N次事务提交会执行fsync进行持久化。比如N=5，mysql就会收集5个binlog后再将这5个binlog一口气同步到磁盘上，好处是一次IO可以往磁盘上刷入
        N个binlog，IO效率会有所提升，坏处是如果mysql收集了4个binlog时，服务器宕机，这4个binlog就会丢失。

（1）根据记录模式和操作触发event事件生成log event（事件触发执行机制）
（2）将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区。
    log event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用与存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。
（3）事务在提交阶段会将产生的log event写入到外部binlog文件中。
    不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。

4、Redo Log 和 BinLog 区别
（1）Redo Log属于InnoDB引擎功能，Binlog属于MySQL Server自带功能，以二进制记录。
（2）Redo Log属于物理日志，记录该数据页更新状态内容，BinLog是逻辑日志，记录更新过程。
（3）Redo Log日志是循环写，日志空间大小是固定的，BinLog是追加写入，写完一个写下一个，不会覆盖使用。
（4）Redo Log作为服务器异常宕机后事务数据自动恢复使用，Binlog可以作为主从复制和数据恢复使用。Binlog没有Crash-safe能力。
    （Crash-safe即在InnoDB存储引擎中，事务提交过程中任何阶段，MySQL突然崩溃，重启后都能保证事务的完整性，已提交的数据不会丢失，未提交完整的数据会自动回滚。这个能力依赖的
    是redo log 和undo log两个日志）

八、RedoLog日志
    redo log重做日志是记录物理数据变化的日志，使用数据库DML对数据的修改操作，都会产生redo log，可以保证事务的持久性。redo log记录了一系列DML操作，因此也可以用来进行数据恢复。
    redo log分为两部分一部分在内存中（redo log buffer），另一部分在磁盘文件中（redo log file），日志先写入内存，再异步持久化到磁盘。
1.数据持久化过程
    Write Ahead Log，日志先行：
        先将旧的数据从磁盘中读入内存；
        再生成一条redo log并写入redo log buffer；
        然后当事务commit时，将redo log buffer中的内容持久化到磁盘文件；
        最后将内存中修改的数据写到磁盘，定期批量执行。
2.为什么要先写日志
    事务采用日志先行来保证数据是持久的，当一个事务提交时，其产生的所有日志必须先写到磁盘中，这样一来，如果在日志写入磁盘后，内存中的数据持久化前数据库发生了宕机，
    那么数据库重启时可以通过日志来保证数据的完整性。    

九、mysql索引建立原则
1、选择唯一性索引
    唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中的学号。
2、为经常需要排序、分组和联合操作的字段建立索引
    经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序会浪费很多时间。
3、为常作为查询条件的字段建立索引
    如果某个字段经常用来做查询条件，那么该字段的查询速度会影响表的查询速度。
4、限制索引数目
    每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。
5、尽量使用数据量少的索引
    如果索引的值很长，查询的速度会受到影响。例如，对一个char(100) 类型的字段进行全文检索需要的时间肯定要比CHAR(10)类型的字段需要的时间长。
6、尽量使用前缀索引
    如果索引字段的值很长，最好使用前缀来索引。
7、删除不再使用或者很少使用的索引
    表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。
8、最左前缀匹配原则
    mysql会一直向右匹配直到遇见范围查询（>、<、between、like）就停止匹配。例如，a=1 and b=2 and c>3 and d=4，如果建立(a,b,c,d)顺序的索引，d就用不到索引，如果是(a,b,d,c)
    的索引则都可以用到，a,b,d的顺序可以任意调整。
9、=和in可以乱序
    比如a=1 and b=2 and c=3建立(a,b,c)可以任意顺序，mysql查询优化器会优化成索引可以识别的形式。
10、尽量选择区分度高的列作为索引
    区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大扫描的记录数越少，唯一键的区分度是1。
11、索引列不能参与计算，保持列“干净”。
    比如from_unixtime(create_time)='2022-06-14'就不能使用索引，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，所以应该写成
    create_time=unix_timestamp('2022-06-14')。
12、尽量扩展索引，不要新建索引。
    比如表中已经有a的索引，现在要加(a,b)的索引那么只需要修改原来的索引即可。
13、当单个索引字段查询数据很多，区分度不大时，则需要考虑建立联合索引来提高查询效率。

十、避免全表扫描方法
1、对查询进行优化，尽量避免全表扫描，首先应考虑在where及order by涉及的列上建索引。
2、尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描。可以给字段设置默认值为0，确保表中的查询列没有null值。
3、尽量避免在where子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行全表扫描。
4、尽量避免在where子句中使用or来连接条件，否则引擎将放弃使用索引而进行全表扫描。
5、避免在索引列上使用计算，也就是避免在where子句中对字段进行表达式操作和函数操作。
6、用具体的字段列表代替‘*’，不要返回用不到的任何字段。
7、用 >= 替代 > 。
9、用where子句替代having子句。

十一、Mysql大表优化

学习链接：  https://mp.weixin.qq.com/s/BMQC2oJlhLoeBDtveXgHpw

1.单表优化
（1）字段优化
    尽量使用TINYINT、SMALLINT、MEDIUM_INT作为整数类型而非INT，如果非负则加上UNSIGNED。
    varchar的长度只分配真正需要的空间。
    使用枚举或整数代替字符串类型。
    尽量使用timestamp而非datetime。
    单表不要有太多字段，建议在20以内。
    避免使用null字段，很难查询优化且占用额外索引空间。
    用整型来存ip
（2）索引
    索引并不是越多越好，要根据查询有针对性的创建，考虑在where和order by命令上涉及的列建立索引，可根据explain来查看是否用了索引还是全表扫描。
    尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描。
    值分布很稀少的字段不适合建索引，例如“性别”这种只有两个值的字段。
    字符字段只建前缀索引。
（3）查询sql
    可通过开启查询慢日志来找出较慢的sql。
    不做列运算：select id where age + 1 = 10，任何对列的操作都将导致表扫描，包括数据库教程函数、计算表达式等等，查询时要尽可能将操作移至
等号右边。
    sql语句尽可能简单：一条sql只能在一个cpu运算；大语句拆小语句，减少锁时间。
    or 改写成in：or的效率是n级别，in的效率是log（n）级别，in的个数建议控制在200以内。
    避免在where子句中使用 != 或 <> 操作符，否则引擎将放弃使用索引而进行全表扫描。
    对于连续数据，使用 between 不用 in 。
（4）读写分离
（5）缓存
（6）垂直拆分
    垂直分库是根据数据库里面的数据表的相关性进行拆分，比如：一个数据库里面既存在用户数据，又存在订单数据，那么垂直拆分可以把用户数据放到用户库、
把订单数据放到订单库。垂直分表是对数据表进行垂直拆分的一种方式，常见的是把一个多字段的大表按常用字段和非常用字段进行拆分，每个表里面的数据记录数
一般情况下是相同的，只是字段不一样，使用主键关联。
    垂直拆分的优点是：
        可以使得行数据变小，一个数据块(Block)就能存放更多的数据，在查询时就会减少I/O次数(每次查询时读取的Block 就少)
        可以达到最大化利用Cache的目的，具体在垂直拆分的时候可以将不常变的字段放一起，将经常改变的放一起
        数据维护简单
    缺点是：
        主键出现冗余，需要管理冗余列
        会引起表连接JOIN操作（增加CPU开销）可以通过在业务服务器上进行join来减少数据库压力
        依然存在单表数据量过大的问题（需要水平拆分）
        事务处理复杂
（7）水平拆分
    水平拆分是通过某种策略将数据分片来存储，分库内分表和分库两部分，每片数据会分散到不同的MySQL表或库，达到分布式的效果，能够支持非常大的数据量。
前面的表分区本质上也是一种特殊的库内分表库内分表，仅仅是单纯的解决了单一表数据过大的问题，由于没有把表的数据分布到不同的机器上，因此对于减轻MySQL
服务器的压力来说，并没有太大的作用，大家还是竞争同一个物理机上的IO、CPU、网络，这个就要通过分库来解决。
    水平拆分的优点是:
        不存在单库大数据和高并发的性能瓶颈
        应用端改造较少
        提高了系统的稳定性和负载能力
    缺点是：
        分片事务一致性难以解决
        跨节点Join性能差，逻辑复杂
        数据多次扩展难度跟维护量极大