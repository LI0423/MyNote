五、一条SQL的执行过程
    首先执行器根据MySQL的执行计划来查询数据，先是从缓存池中查询数据，如果没有就会去数据库中查询，如果查询到了就将其放到缓存池中，在数据被缓存到缓存池的同时，
    会写入undo log日志文件。更新的动作是在BufferPool中完成的，同时会将更新后的数据添加到redo log buffer中。完成以后就可以提交事务，在提交的同时会做以下
    三件事：将redo log buffer中的数据刷入到redo log文件中；将本次操作记录写入到bin log文件中；将bin log文件名字和更新内容在bin log中的位置记录到redo
    log中，同时在redo log最后添加commit 标记。
    
六、MySQL宕机时数据不丢失的原理
    MySQL在更新数据时，为了减少磁盘的随机IO，因此并不会直接更新磁盘上的数据，而是先更新Buffer Pool中缓存页的数据，等到合适的时间点，再将这个缓存页持久化到磁盘。
    而Buffer Pool中所有缓存都是处于内存当中的，当MySQL宕机或者机器断电，内存中的数据就会丢失。当进行增删操作时，MySQL会在更新Buffer Pool中的缓存页数据时，
    会记录一条对应操作的redo log日志，当出现宕机或者断电时，如果有缓存页的数据还没来得急刷入磁盘，当MySQL重新启动时，可以根据redo log日志文件进行数据重做，
    将数据恢复到宕机或者断电前的状态，保证了更新的数据不丢失，因此redolog叫做重做日志，本质是保证事务提交后更新的数据不丢失。
    redo log中记录的是对物理磁盘上某个表空间的某个数据页的某一行数据的某个字段做的修改，修改后的值是多少。redolog日志文件是持久化在磁盘上的，磁盘上可以有多个
    redo log 文件，默认有两个文件，每个文件大小为48MB。
1、如何保证数据不丢失
（1）Mysql Server层的执行器调用InnoDB存储引擎的数据更新接口；
（2）存储引擎更新Buffer Pool中的缓存页；
（3）同时存储引擎记录一条redo log到redo log buffer中，并将该条redo log的状态标记为prepare状态；
（4）接着存储引擎告诉执行器，可以提交事务了，执行器接到通知后会写binlog日志，然后提交事务；
（5）存储引擎接到提交事务的通知后，将redo log的日志状态标记为commit状态；
（6）接着根据innodb_flush_log_at_commit参数的配置，决定是否将redo log buffer中的日志刷入磁盘。

2、两阶段事务提交
    将redolog 日志标记为prepare和commit状态，这种就是两阶段事务提交。redolog在进行重做的时候，只有读到了commit标识，才会认为这条redo log日志是完整的，
    才会进行数据重做，否则会认为这条redo log日志不完整，不会进行数据重做。

七、BinLog日志
    binlog日志是记录所有数据库表结构变更以及表数据修改的二进制日志文件，不会记录select和show这类操作。
    是mysql服务层产生的日志，常用来进行数据恢复、数据库复制，常见的mysql主从架构就是采用slave同步master的binlog实现的，另外通过解析binlog能够实现mysql到其他数据源（ES）的数据复制。
1、使用场景
（1）主从复制：在主库中开启Binlog功能，主库可以把Binlog传递给从库，从库拿到Binlog后实现数据恢复达到主从数据一致性。
（2）数据恢复：通过mysql binlog工具来恢复数据。

2、文件记录模式
（1）Row
    日志记录每一行数据被修改的情况，然后在slave端对相同数据进行修改。
    优点：能清楚记录每一个行数据的修改细节，能完全实现主从数据同步和数据的恢复。
    缺点：批量操作，会产生大量的日志，尤其是alter table会让日志暴涨。
（2）Statement
    每一条被修改数据的SQL都会记录到master的binlog中，slave在复制的时候SQL进程会解析成和原来master端执行过的相同的SQL再次执行。
    优点：日志量小，减少磁盘IO，提升存储和恢复速度。
    缺点：在某些情况下会导致主从数据不一致，比如last_insert_id()、now()等函数。
（3）Mixed
    以上两种模式的混合使用，一般会使用Statement模式保存binlog，对于statement模式无法复制的操作使用row模式保存binlog，mysql会根据执行的sql语句选择写入模式。

3、Binlog写入机制
    常见的log event有：Query event、Row event、Xid event等。binlog 文件的内容就是各种Log event的集合。
    在事务执行过程中，先把日志写到binlog cache，事务提交的时候再把binlog cache写到binlog文件中。
    binlog cache在每个线程内空间独立的，如果启用了binlog日志，mysql会为每个session分配一个二进制日志缓存，如果经常使用大型事务，则可以增加此缓存大小来获得更好的性能，可以通过
    binlog_cache_size配置其大小，默认为32768bytes。如果binlog cache空间足够，在事务提交的时候，cache中的内容会被清空，同时这些数据会被写入到binlog files中。因为binlog
    内容无论多大在事务提交时都需要一次性写入，所以当binlog cache放不下的时候，就需要暂存到磁盘，然后提交被写入到binlog files。
    写入到binlog中又拆分为两部分：
        write：首先会写入page cache中的binlog files中，page cache就是一块内存。（不占用磁盘IOPS）
        fsync：然后操作系统执行fsync时binlog才会从page cache中真正持久化到磁盘。（占用磁盘IOPS）
    write和fsync时机：
        sync_binlog=0：表示innodb不会主动控制将binlog落盘，innodb仅仅会将binlog写入到page cache中，至于什么时间将binlog刷入磁盘中完全依赖于操作系统，选这种策略，一旦操作系统宕机，
        page cache中的binlog就会丢失。每次提交事务只是write，不执行fsync，也就是binlog不做持久化。
        sync_binlog=1：表示事务commit时将binlog落盘，哪怕机器宕机了也能确保binlog会被写入到磁盘中。每次提交事务都要发生fsync。
        sync_binlog=N：表示每次事务都会write，但是N次事务提交会执行fsync进行持久化。比如N=5，mysql就会收集5个binlog后再将这5个binlog一口气同步到磁盘上，好处是一次IO可以往磁盘上刷入
        N个binlog，IO效率会有所提升，坏处是如果mysql收集了4个binlog时，服务器宕机，这4个binlog就会丢失。

（1）根据记录模式和操作触发event事件生成log event（事件触发执行机制）
（2）将事务执行过程中产生log event写入缓冲区，每个事务线程都有一个缓冲区。
    log event保存在一个binlog_cache_mngr数据结构中，在该结构中有两个缓冲区，一个是stmt_cache，用与存放不支持事务的信息；另一个是trx_cache，用于存放支持事务的信息。
（3）事务在提交阶段会将产生的log event写入到外部binlog文件中。
    不同事务以串行方式将log event写入binlog文件中，所以一个事务包含的log event信息在binlog文件中是连续的，中间不会插入其他事务的log event。

4、Redo Log 和 BinLog 区别
（1）Redo Log属于InnoDB引擎功能，Binlog属于MySQL Server自带功能，以二进制记录。
（2）Redo Log属于物理日志，记录该数据页更新状态内容，BinLog是逻辑日志，记录更新过程。
（3）Redo Log日志是循环写，日志空间大小是固定的，BinLog是追加写入，写完一个写下一个，不会覆盖使用。
（4）Redo Log作为服务器异常宕机后事务数据自动恢复使用，Binlog可以作为主从复制和数据恢复使用。Binlog没有Crash-safe能力。
    （Crash-safe即在InnoDB存储引擎中，事务提交过程中任何阶段，MySQL突然崩溃，重启后都能保证事务的完整性，已提交的数据不会丢失，未提交完整的数据会自动回滚。这个能力依赖的
    是redo log 和undo log两个日志）

八、RedoLog日志
    redo log重做日志是记录物理数据变化的日志，使用数据库DML对数据的修改操作，都会产生redo log，可以保证事务的持久性。redo log记录了一系列DML操作，因此也可以用来进行数据恢复。
    redo log分为两部分一部分在内存中（redo log buffer），另一部分在磁盘文件中（redo log file），日志先写入内存，再异步持久化到磁盘。
1.数据持久化过程
    Write Ahead Log，日志先行：
        先将旧的数据从磁盘中读入内存；
        再生成一条redo log并写入redo log buffer；
        然后当事务commit时，将redo log buffer中的内容持久化到磁盘文件；
        最后将内存中修改的数据写到磁盘，定期批量执行。
2.为什么要先写日志
    事务采用日志先行来保证数据是持久的，当一个事务提交时，其产生的所有日志必须先写到磁盘中，这样一来，如果在日志写入磁盘后，内存中的数据持久化前数据库发生了宕机，
    那么数据库重启时可以通过日志来保证数据的完整性。    
3.二阶段提交原理
    第一阶段（prepare阶段）：写redolog并将其标记为prepare状态。
    第二阶段（commit阶段）：写binlog并将其标记为commit状态。
4.采用二阶段提交的原因
    主要是为了保证redolog和binlog数据的安全一致性。只有这两个日志文件逻辑上高度一致，才能放心使用redolog将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复以及主从复制。
（1）先写redolog再写binlog
    如果在一条语句写入redolog之后崩溃了，binlog则没有记录这条语句。系统在crash recovery时重新执行了一遍binlog便会少了这一次的修改。恢复的数据库少了这条更新。
（2）先写binlog再写redolog
    如果在一条语句写入binlog之后崩溃了，redolog则没有记录这条语句（数据库物理层面并没有执行这条语句）。系统在crash recovery时重新执行了一遍binlog便会多了这一次的修改。恢复
    的数据库便多了这条更新。
5.Crash Recovery
    在做crash recovery时分为三种情况：
        binlog有记录，redolog状态commit：正常完成的事务，不需要恢复；
        binlog有记录，redolog状态prepare：在binlog写完提交事务之前的crash，恢复操作：提交事务（因为之前没有提交）。
        binlog无记录，redolog状态prepare：在binlog写完之前的crash，恢复操作：回滚事务（因为crash时并没有成功写入数据库）。
6.组提交
（1）日志逻辑序列号（log sequence number，LSN），LSN是单调递增的，用来对应redo log的一个个写入点；每次写入长度为length的redolog，
    LSN的值就会加上length；LSN也会写到InnoDB的数据页中，来确保数据页不会被多次执行重复的redolog。
（2）为了提高并发性能，mysql引入了binlog的组提交功能，prepare阶段不变，只针对commit阶段，将commit阶段拆分为三个过程：
        flush stage：多个线程进入顺序将binlog从cache写入文件（不刷盘）；
        sync stage：对binlog文件做fsync操作（多个线程的binlog合并一次刷盘）；
        commit stage：各个线程按顺序做InnoDB commit操作。
    每个阶段都有lock保护，因此保证了事务写入的顺序。
    在每个stage设置一个队列，第一个进入该队列的线程会成为leader，后续进入的会阻塞支持完成提交。leader线程会领导队列中的所有线程执行该stage的任务，并带领所有follower进入到下一个stage去执行，
    当遇到下一个stage为非空队列时，leader会变成follower注册到该队列中。
    5.7版本中修改了组提交的flush阶段，在prepare阶段不再让线程各自执行flush redolog操作，而是推迟到组提交的flush阶段，flush stage修改如下逻辑：
        收集组提交队列，得到leader线程，其余follower线程进入阻塞；
        leader调用ha_flush_logs做一次redo write/sync，一次将所有线程的redolog刷盘；
        将队列中的线程的所有binlog cache写到binlog文件中。
（3）一次组提交里面，组员越多，节约磁盘IOPS的效果越好。在并发更新场景下，第一个事务写完redolog buffer以后，越晚执行fsync，组员可能越多，节约
    磁盘IOPS的效果越好。

7.redo log写入策略
    为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数，有三种取值：
    设置为0时，表示每次事务提交时都只是把redo log留在redo log buffer中；
    设置为1时，表示每次事务提交时都将redo log直接持久化到磁盘；
    设置为2时，表示每次事务提交时都只是把redo log写到page cache。

十、避免全表扫描方法
1、对查询进行优化，尽量避免全表扫描，首先应考虑在where及order by涉及的列上建索引。
2、尽量避免在where子句中对字段进行null值判断，否则将导致引擎放弃使用索引而进行全表扫描。可以给字段设置默认值为0，确保表中的查询列没有null值。
3、尽量避免在where子句中使用!=或<>操作符，否则引擎将放弃使用索引而进行全表扫描。
4、尽量避免在where子句中使用or来连接条件，否则引擎将放弃使用索引而进行全表扫描。
5、避免在索引列上使用计算，也就是避免在where子句中对字段进行表达式操作和函数操作。
6、用具体的字段列表代替‘*’，不要返回用不到的任何字段。
7、用 >= 替代 > 。
9、用where子句替代having子句。

十二、视图
    一个或者多个数据表里的数据的逻辑显示，视图并不存储数据。
1、理解视图
    视图的创建和删除只影响视图本身，不影响对应的基表。但是当对视图中的数据进行增加、删除和修改操作时，数据表中的数据会相应地发生变化，反之亦然。
    向视图提供数据内容的语句为select语句。
2、创建视图
    create [or replace]
    [algorithm = {undefined | merge | temptable}]
           merge：引用视图和视图定义的语句的文本被合并，使视图定义的部分取代语句的相应部分。
           temptable：视图中的结果被检索到一个临时表中，然后用来执行语句，视图将不支持更新操作。
           undefined：mysql选择使用哪种算法，如果可能的话，更倾向于merge而不是temptable，因为merge通常更有效率。
    view 视图名称
    as 查询语句
    [with [cascaded | local] check option]
3、不可更新的视图
    要使视图可更新，视图中的行和底层基本表中的行之间必须存在一对一的关系。一下情况不可更新
        在定义视图的时候指定了“algorithm=tempatble”，视图将不支持insert和delete操作；
        视图中不包含基本表中所有被定义为非空又未指定默认值的列，视图将不支持insert操作；
        在定义视图的select语句中使用了join联合查询，视图将不支持insert和delete操作；
        在定义视图的select语句后的字段列表中使用了数学表达式或子查询，视图将不支持insert，也不支持update使用了数学表达式、子查询的字段值；
        在定义视图的select语句后的字段列表中使用了distinct、聚合函数、group by、having、union等，视图将不支持insert、update、delete；
        在定义视图的select语句中包含了子查询，而子查询中引用了from后面的表，视图将不支持insert、update、delete；
        视图定义基于一个不可更新视图；
        常量视图。
4、修改、删除视图
    使用create or replace
    alter view 视图名称 as 查询语句
    删除视图
        drop view if exists 视图名称
        drop view if exists 视图名称1，视图名称2，视图名称3
5、优点
（1）操作简单
（2）减少数据冗余
    视图跟实际数据表不一样，它存储的是查询语句。所以在使用的时候要通过定义视图的查询语句来获取结果集。而视图本身不存储数据，不占用数据存储的资源。
（3）数据安全
    mysql将用户对数据的访问限制在某些数据的结果集上，而这些数据的结果集可以使用视图来实现。用户不必直接查询或操作数据表。也可以理解为视图具有隔离性。
（4）适应灵活多变的需求
（5）能够分解复杂的查询逻辑
    数据库中如果存在复杂的查询逻辑，则可以将问题进行分解，创建多个视图获取数据，再将创建的多个视图结合起来，完成复杂的查询逻辑。
6、缺点
    如果在实际数据表上创建了视图，那么当实际数据表的结构变更了，就需要及时对相关的视图进行维护。

十三、事务隔离级别
    Read uncommitted（读未提交）：最低的隔离级别，允许读取尚未提交的数据变更，可以防止更新丢失，可能会导致脏读、不可重复读或幻读。
    Read committed（读已提交）：允许读取并发事务已经提交的数据，可以防止更新丢失、脏读，可能会导致不可重复读或幻读。
    Repetable read（可重复读）：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以防止更新丢失、脏读和不可重复读，可能会导致幻读。
    Serializable（串行化）：最高的隔离级别，完全服从ACID的隔离级别，所有的事务依次执行。可以防止更新丢失、脏读、不可重复读和幻读。

    查看当前数据库的事务隔离级别：
        show variables like 'tx_isolation';

    
数据删除流程：
    如果要删除一条记录，InnoDB引擎会把这条记录标记为删除。如果之后再插入一条记录，可能会复用这个位置。但是磁盘文件的大小并不会缩小。
    如果删除一个数据页上的记录，整个数据页可以被复用。记录的复用只限于符合范围条件的数据。而当整个页从B+树里面摘掉以后，可以复用到
    任何位置。
    如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。
    如果用delete命令把整个表的数据删除，所有的数据页都会被标记为可复用。但是磁盘上，文件不会变小。
    delete命令其实只是把记录的位置，或者数据页标记为可复用，但磁盘文件的大小是不会变的。也就是说，通过delete命令是不能回收表空间的，
    这些可以复用，而没有被使用的空间，看起来就像是空洞。
    不止删除数据会产生空洞，插入数据也会。
    如果数据是按照索引递增顺序插入的，索引是紧凑，但是如果是随机插入的，就可能造成索引的数据页分裂。如果数据页满了，再插入一条数据，就
    需要申请一个新的数据页来保存数据。页分裂完成后，原本的数据页末尾就留下了空洞。另外，更新索引上的值，可以理解为删除一个旧值，再插入
    一个新值。也会产生空洞。也就是说，经过大量增删改的表，都是可能存在空洞的。

重建表：
    为了把表中的空洞去掉，可以使用alter table A engine=InnoDB命令来重建表。
Online DDL重建表流程：
    建立一个临时文件，扫描表A主键的所有数据页；
    用数据页中表A的记录生成B+树，存储到临时文件中；
    生成临时文件的过程中，将所有对A的操作记录在一个日志文件（row log）中；
    临时文件生成后，将日志文件中的操作应用到临时文件中，得到一个逻辑数据上与表A相同的数据文件；
    用临时文件替换表A的数据文件。

自增id
1.自增值保存位置
（1）MyISAM引擎的自增值保存在数据文件中。
（2）InnoDB引擎的自增值也保存在内存里，到了8.0版本后，才有了自增值持久化的的能力，实现了发生重启，表的自增值可以恢复为MySQL重启前的值。
    在5.7及之前的版本，自增值保存在内存里，没有持久化，每次重启后，第一次打开表的时候，都会去找自增值的最大值max(id)，然后将max(id)+1
    作为这个表当前的自增值。
    在8.0版本，将自增值的变更记录在了redo log中，重启的时候依靠redo log恢复重启前的版本。
2.自增值修改机制
    要插入的值是X，当前自增值是Y。如果X<Y，那么表的自增值不变；如果X>=Y，就要把当前自增值修改为新的自增值。
3.自增值的修改时机
    在真正执行插入数据的操作之前。
    唯一键冲突会导致自增主键id不连续；事务回滚也会造成不连续。

