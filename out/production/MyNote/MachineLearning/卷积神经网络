一、层级结构
    数据输入层（Input layer）
    卷积计算层（CONV layer）
    ReLU激励层（ReLU layer）
    池化层（Pooling layer）
    全连接层（FC layer）
1、数据输入层
    主要是针对原始图像进行预处理
（1）去均值：把输入数据各个维度都中心化为0。
（2）归一化：幅度归一化到同样的范围，即减少各维度数据取值范围的差异而带来的干扰。
（3）PCA/白化：用PCA降维；白化是对数据各个特征轴上的幅度归一化。
2、卷积计算层
    深度：有多少个神经元，深度就是多少。
    步幅：窗口一次滑动的长度。
    填充值：zero padding
（1）提取特征
    局部感受野：局部范围内的像素之间联系较为紧密，而距离较远的的像素则相关性较弱。所以每个神经元没必要对全局图像进行感知，只需要对局部进行感知，
    然后在更高层讲局部的信息综合起来得到全局的信息。
（2）卷积
    当给定一张新图时，CNN并不能准确地知道这些特征要匹配原图的哪些部分，所以会在原图中把每一个可能的位置都进行尝试，相当于把这个feature变成了
    一个过滤器。这个用来匹配的过程被称作卷积操作。
    步幅控制着过滤器围绕输入内容进行卷积计算的方式，过滤器移动的距离就是步幅，步幅的设置通常要确保输出内容是一个整数而非分数。
（3）填充值
    在网络早期层，想要尽可能保留原始输入内容的信息，这样就能提取出那些低层的特征。零填充在输入内容的边界周围补充零。如果步幅为1，而且零填充
    设置为 zero padding = (K - 1) / 2。K 是过滤器尺寸，那么输入和输出内容总能保持一致的空间维度。计算任意给定卷积层的输出的大小的公式
    是 O = (W - K + 2P) / S + 1。O 是输出尺寸，W 是输入图像的高度或宽度， K 是过滤器尺寸，P 是填充，S 是步幅。