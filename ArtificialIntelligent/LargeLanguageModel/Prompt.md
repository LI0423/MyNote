# Prompt Engineer

Prompt是一种基于人工智能（AI）指令的技术，通过明确而具体的指导语言模型的输出。在提示词工程中，Prompt的定义涵盖了任务、指令和角色三个主要元素，以确保模型生成符合用户需求的文本。

## 模型设置

**Temperature**：控制模型生成文本的确定性，大部分模型中temperature范围为(0-1]。接近0时，模型倾向于选择概率最高的输出，使生成的文本更加确定、一致。接近1时，模型倾向于按照概率分布随机选择输出，使输出的文本更加多样化。

**Top_p**：控制模型返回结果的确定性。只有词元集合中包含top_p概率质量的才会被考虑用于响应，较低的top_p值会选择最有信心的响应。较高的top_p将使模型考虑更多可能的词语，包括不太可能的词语。如果需要准确和事实的答案，就把参数调低。如果在寻找更多样化的响应，可以将其值调高一点。

**Max Length**：控制模型生成的token数。指定Max Length有助于防止大模型生成冗长或不相关的响应并控制成本。

**Stop Sequence**：是一个字符串，可以阻止模型生成token，控制大模型响应长度和结构的另一种方法。例如，通过添加“11”作为stop sequence来告诉模型生成不超过10个项的列表。

**Frequency Penalty**：对下一个生成的token进行惩罚，这个惩罚和token在响应和提示中已出现的次数成比例。frequency penalty越高，某个词再次出现的可能性就越小，这个设置通过给重复数量多的Token设置更高的惩罚来减少响应中单词的重复。

**Presence Penalty**：也是对重复的token施加惩罚，但与frequency penalty不同的是，惩罚对于所有重复token都是相同的。出现两次的token和出现10次的token会受到相同的惩罚。可以防止模型在响应中过于频繁地生成重复的词。更高的presence penalty，模型生成多样化或创造性的文本；更低的presence penalty，模型生成更专注的内容。

## 提示词要素

提示词可以包含以下任意要素：

**指令**：想要模型执行的特定任务或指令。

**上下文**：包含外部信息或额外的上下文信息，引导语言模型更好地响应。

**输入数据**：用户输入的内容或问题。

**输出指示**：指定输出的类型或格式。
