# 贝叶斯滤波

## 核心思想

无法确切地知道事物的真实状态，但可以通过不断结合新的证据（传感器数据）来更新和改善所有可能状态及其对应的可能性。

## 两大基础

### 贝叶斯定理

后验概率 = （似然度 * 先验概率） / 证据

### 马尔科夫假设

当前状态$x_t$只依赖于它前一个状态$x_{t-1}$（由控制$u_t$驱动），而与更早的历史无关；当前的预测$z_t$只依赖于当前状态$x_t$。

## 流程

贝叶斯滤波是一个递归算法，在两个步骤之间不断循环：

1. 预测：根据历史信念和运动模型，预测当前状态。
2. 更新：拿到新的传感器数据后，修正这个预测。

### 数学公式

$$bel(x_{t-1}) = p(x_{t-1} | z_{1:t-1}, u_{1:t-1})$$

### 第一步：预测

在获得新的观测$z_t$之前，利用系统模型（状态转移模型）来预测当前状态会是什么样子。

$$p(x_t | z_{1:t-1}, u_{1:t}) = \int p(x_t | x_{t-1}, u_t) * p(x_{t-1} | z_{1:t-1}, u_{1:t-1}) dx_{t-1}$$

- $p(x_t | x_{t-1}, u_t)$：这是系统模型，描述了如果上一时刻状态是$x_{t-1}$，并且执行了控制$u_t$，那么当前状态是$x_t$的概率是多少。这个模型包含了过程的不确定性（噪声）。
- $p(x_{t-1} | z_{1:t-1}, u_{1:t-1})$：这是上一时刻的信念$bel(x_{t-1})$。
- 积分：这个操作是对所有可能的上一时刻状态$x_{t-1}$进行加权平均。结果是预测信念，或者叫先验概率分布。记作：$bel(x_t)=p(x_t | z_{1:t-1}, u_{1:t})$。

### 第二步：更新

根据新的观测数据$z_t$修正预测。

$$p(x_t | z_{1:t}, u_{1:t}) = \eta * p(z_t | x_t) * p(x_t | z_{1:t-1}, u_{1:t})$$

- $p(z_t | x_t)$：这是观测模型。描述了如果当前状态是$x_t$，那么观测到$z_t$的概率是多少。衡量了传感器测量的可靠性。
- $p(x_t | z_{1:t-1}, u_{1:t})$：这就是上一步得到的预测信念（先验）bel(x_t)。
- $\eta$：是一个归一化常数，确保最终的概率分布总和为1。
- 结果$p(x_t | z_{1:t}, u_{1:t})$这就是最终想要的后验概率分布，即更新后的信念：$bel(x_t) = \eta * p(z_t | x_t) * bel(x_t)$

## 贝叶斯滤波家族

贝叶斯滤波是一个理论框架。本身没有解析解，因为其中的积分可能非常难计算。不同的滤波算法就是这个框架在不同假设下的具体实现：

- 卡尔曼滤波：当系统模型和观测模型都是线性的，并且所有噪声都是高斯分布时，贝叶斯滤波的解析解就是卡尔曼滤波。
- 扩展卡尔曼滤波：当系统是非线性的，但在局部可以近似为线性时使用。
- 无迹卡尔曼滤波：另一种处理非线性的方法，比EKF更优雅。
- 粒子滤波：当系统是强非线性、非高斯时，使用粒子滤波。粒子滤波采用一大群随机样本（粒子）来近似表示概率分布$bel(x_t)$，从而实现了贝叶斯滤波框架。
