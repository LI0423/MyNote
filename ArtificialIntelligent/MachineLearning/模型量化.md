# 模型量化

通过降低模型参数的数值精度来减小模型大小、提升推理速度。

## 量化方法

- 动态量化：在推理时动态计算量化参数
- 静态量化：使用校准数据预先确定量化参数
- 量化感知训练：在训练过程中模拟量化效果
- 后训练量化：训练完成后对模型进行量化

## 量化效果评估标准

- 精度保持：精度损失最小化
- 模型大小
- 推理速度：延迟显著降低
- 内存占用：峰值内存降低
- 能耗效率：能效显著提升

## 量化操作

### PyTorch动态量化

```Python
import torch
import torchvision
from torch.quantization import quantize_dynamic


# 加载预训练模型
model_fp32 = torchvision.models.resnet18(pretrained=True)
model_fp32.eval()

# 动态量化（主要量化Linear和LSTM层）
model_int8 = quantize_dynamic(
    model_fp32, # 原始模型
    {torch.nn.Linear, torch.nn.LSTM}, # 要量化的模块类型
    dtype=torch.qint8
)

# 保存量化模型
torch.save(model_int8.state_dict(), 'resnet18_dynamic_quantized.pth')
print(f"原始模型大小: {sum(p.numel() for p in model_fp32.parameters())} 参数")
print(f"量化模型大小: {sum(p.numel() for p in model_int8.parameters())} 参数")
```

### PyTorch静态量化

```Python
import torch
import torchvision
import torch.quantization
import torch.nn as nn
from torch.quantization import QuantStub, DeQuantStub


# 准备校准数据
def prepare_calibration_data():
    # 使用ImageNet的均值和标准差
    transform = torchvision.transforms.Compose([
        torchvision.transforms.Resize(256),
        torchvision.transforms.CenterCrop(224),
        torchvision.transforms.ToTensor(),
        torchvision.transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
    ])

    # 使用验证集的一部分进行校准
    calibration_loader = torchvision.datasets.ImageNet(
        root='path/to/imagenet',
        split='val',
        transform=transform
    )

    # 取100张图片进行校准
    calibration_loader = torch.utils.data.DataLoader(
        calibration_dataset,
        batch_size=32,
        shuffle=True,
        num_workers=4
    )
    return calibration_loader

# 静态量化过程
def static_quantization_example():
    # 加载模型
    model = torchvision.models.resnet18(pretrained=True)
    model.eval()

    # 模型融合，主要将多个量化操作合并为一个模块，减少计算冗余并优化模型部署。
    model.fuse_model()
    # 准备量化模型
    torch.quantization.prepare(model, inplace=True)
    # 校准 - 运行一些数据来确定量化参数
    calibration_loader = prepare_calibration_data()
    with torch.no_grad():
        for data, _ in calibration_loader:
            if len(data) > 1000:
                break
            model(data)

    # 转换为量化模型
    model_int8 = torch.quantization.convert(model, inplace=False)
    return model_int8

# 执行静态量化
quantized_model = static_quantization_example()
print("静态量化完成！")
```

### ONNX模型静态量化

```Python
import onnx
import onnxruntime as ort
from onnxruntime.quantization import quantize_dynamic, quantize_static, QuantFormat, QuantType
import numpy as np


def onnx_quantization_example():
    # 假设我们有一个原始的ONNX模型
    original_model_path = "resnet18.onnx"
    quantized_model_path = "resnet18_quantized.onnx"
    
    # 方法1: 动态量化
    quantize_dynamic(
        original_model_path,
        quantized_model_path,
        weight_type=QuantType.QUInt8
    )
    
    # 方法2: 静态量化（需要校准数据集）
    def get_calibration_data():
        # 返回校准数据集的生成器
        for i in range(100):  # 100个批次
            yield {'input': np.random.randn(1, 3, 224, 224).astype(np.float32)}
    
    # 需要安装 onnxruntime-extensions
    from onnxruntime.quantization import CalibrationDataReader
    
    class CustomDataReader(CalibrationDataReader):
        def __init__(self):
            self.iterator = get_calibration_data()
        
        def get_next(self):
            return next(self.iterator, None)
    
    # 执行静态量化
    quantize_static(
        original_model_path,
        quantized_model_path,
        calibration_reader=CustomDataReader()
    )
    
    return quantized_model_path
```

### 量化感知训练

```Python
import torch
import torch.nn as nn
import torch.quantization
import torch.optim as optim

class QuantizableModel(nn.Module):
    def __init__(self):
        super(QuantizableModel, self).__init__()
        self.quant = torch.quantization.QuantStub()
        self.dequant = torch.quantization.DeQuantStub()
        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.fc = nn.Linear(128 * 56 * 56, 10)
    
    def forward(self, x):
        x = self.quant(x)
        x = self.relu1(self.conv1(x))
        x = self.relu2(self.conv2(x))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        x = self.dequant(x)
        return x
    
    def fuse_model(self):
        # 融合Conv+ReLU层
        torch.quantization.fuse_modules(self, [['conv1', 'relu1'], ['conv2', 'relu2']], inplace=True)

def quantization_aware_training():
    # 创建模型
    model = QuantizableModel()
    model.train()
    
    # 融合模型
    model.fuse_model()
    
    # 设置量化配置
    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')
    
    # 准备QAT
    torch.quantization.prepare_qat(model, inplace=True)
    
    # 训练循环（简化版）
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    for epoch in range(10):
        # 假设有训练数据
        for data, target in train_loader:
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
        
        print(f'Epoch {epoch+1}, Loss: {loss.item()}')
    
    # 转换为量化模型
    model.eval()
    quantized_model = torch.quantization.convert(model, inplace=False)
    
    return quantized_model

# 执行QAT
qat_model = quantization_aware_training()
```

### 量化效果验证

```Python
def validate_quantization(original_model, quantized_model, test_loader):
    original_model.eval()
    quantized_model.eval()

    original_correct = 0
    quantized_correct = 0
    total = 0

    with torch.no_grad():
        for data, target in test_loader:
            original_output = original_model(data)
            original_pred = original_output.argmax(dim=1)
            original_correct += original_pred.eq(target).sum().item()

            quantized_output = quantized_model(data)
            quantized_pred = quantized_output.argmax(dim=1)
            quantized_correct += quantized_pred.eq(target).sum().item()

            total += target.size(0)

    original_accuracy = 100. * original_correct / total
    quantized_accuracy = 100. * quantized_correct / total

    print(f"原始模型精度: {original_accuracy:.2f}%")
    print(f"量化模型精度: {quantized_accuracy:.2f}%")
    print(f"精度损失: {original_accuracy - quantized_accuracy:.2f}%")
    
    return original_accuracy, quantized_accuracy
```
