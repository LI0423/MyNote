Hive 

一、shell基本命令
1.beeline常用操作
    （1）使用jdbc连接到远程hiveserver实例。
        beeline -u <url> -n <username> -p <password>
    （2）退出beeline客户端    !quit 或 !q
    （3）使用一个查询语句       beeline -e "query_string"

二、相关函数
1.get_json_object函数
    get_json_object(string json_string,string path)
    第一个参数是json对象变量，第二个参数使用 $ 表示json变量标识 

    例如：
        data = 
        {
            "store":
                    {
                        "fruit":[{"weight":8,"type":"apple"},{"weight":9,"type":"pear"}],
                        "bicycle":{"price":19.95,"color":"red"}
                    },
            "email":"1234@qq.com",
            "owner":"ltj"
        }
    
    get单层值：
        select get_json_object(data,'$.owner') from test;
    
    get多层值：
        select get_json_object(data,'$.store.bicycle.price') from test;

    get数组值：
        select get_json_object(data,'$.store.fruit[0]') from test;

2.parse_url函数 
    parse_url(url,partToExtract[key])
    partToExtract 的选项包含 [HOST,PATH,QUERY,REF,PROTOCOL,FILE,AUTHORITY,USERINFO]

    例如：
        https://www.baidu.com/ltj?user_id=12345&paltform=ios

        获取PROTOCOL
        select parse_url('https://www.baidu.com/ltj?user_id=12345&paltform=ios','PROTOCOL') from test;
        结果：https

        获取QUERY
        select parse_url('https://www.baidu.com/ltj?user_id=12345&paltform=ios','QUERY') from test;
        结果：user_id=12345&paltform=ios
        
        获取QUERY中的指定参数的值
        select parse_url('https://www.baidu.com/ltj?user_id=12345&paltform=ios','QUERY','user_id') from test;
        结果：12345

3.reflect函数
    reflect('Java包名','方法名',data)
    reflect函数支持在sql中调用Java自带的函数

    例如：
        （1）所有记录执行相同的Java内置函数
        表中数据：column1,column2
            1,2
            2,3
            3,4

            select reflect('java.lang.Math','max',column1,column2) from test;
            结果：2 3 4
        （2）不同记录执行不同的Java内置函数
        表中数据：class_name(string),method_name(string),column1,column2
            java.lang.Math,min,1,2
            java.lang.Math,max.2,3

            select reflect(class_name,method_name,column1,column2) from test;
            结果：1 3
        （3）使用apache commons中的函数，commons下的jar已经包含在hadoop的classpath中，所以可以直接使用。
            select reflect('org.apache.commons.lang.math.NumberUtils','isNumber','123') from test;
            结果：true
4.regexp_replace函数
    regexp_replace(string INITIAL_STRING,string PATTERN,string REPLACEMENT)
    把 INITIAL_STRING 中与 PATTERN 相匹配的子串替换为 REPLACEMENT
    用两个反斜杠代替一个，一个反斜杠用来转义。
5.regexp_extract函数
    regexp_extract(string subject,string pattern,int index)
    将字符串 subject 按照 pattern 正则表达式的规则拆分，返回 index 指定的字符
6.from_unixtime函数
    from_unixtime(unix_timestamp(),'yyyy-MM-dd HH:mm:ss')
    获取当前时间戳并将其转换为日期形式。
    返回值：string
7.unix_timestamp函数
    unix_timestamp(string date)
    如果参数date满足 yyyy-MM-dd HH:mm:ss 形式，则可以直接得到参数对应的时间戳
    如果不满足则需要指定date的形式再进行转换，unix_timestamp('20220113','yyyyMMdd')
    返回值：bigint
8.round函数
    round(double a)
    取整函数，返回double类型的整数值部分（遵循四舍五入）
    例如：
        select round(3.1415926) from table;
        结果：3

    round(double a,int b)
    返回指定精度的double类型（遵循四舍五入）
    例如：
        select round(3.1415926,4) from table;
        结果：3.1416
9.floor函数
    floor(double a)
    向下取整函数，返回等于或者小于该double变量的最大的整数
    例如：
        select floor(3.1415926) from table;
        结果：3
10.ceil和ceiling函数
    ceil(3.1415)，ceiling(3.1415)
    向上取整函数，返回等于或者大于该double变量的最小的整数
    例如：
        select ceil(3.1415) from table;
        结果：4
11.COALESCE函数
    COALESCE(T v1, T v2, ...)
    返回参数中的第一个非空值；如果所有值都为null，那么返回null
    例如：
        select COALESCE(null,'100','500') from table;
        结果：100
12.explode函数
    将一行数据转换成列数据，可用于array和map类型
    用于array:
        select explode(arraycol) as newcol from table;
        arraycol:array数据类型的列名。
        newcol:给转换成的列命名一个新的名字，用于代表转换之后的列名。
    用于map:
        select explode(mapcol) as (key,value) from table;
        map是key-value结构，在转换的时候会转换成两列，一列是key转换成的，一列是value转换成的。
13.lateral view
    Hive提供给UDTF的结合，可以解决UDTF不能添加额外select列的问题。是用来和像explode这种UDTF函数联用的，会将UDTF生成的结果放到一个虚拟表中，
    虚拟表会和输入行进行join来达到连接UDTF外的select字段的目的。
    格式一：
        lateral view udtf(expression) tableAlias as columnAlias (,columnAlias)*
        lateral view 在UDTF前使用，表示连接UDTF所分裂的字段。
        tableAlias:表示UDTF转换的虚拟表的名称。
        columnAlias:表示虚拟字段名称，如果分裂之后有一个列，则写一个即可；如果分裂之后有多个列，按照列的顺序在括号中声明所有虚拟列名，以逗号隔开。
    格式二：
        from table (lateral view)*
        在from子句中使用，一般和格式一搭配使用，这个格式只是说明了lateral view 的使用位置。from子句可以跟多个lateral view语句，使用空格间隔。
    格式三：
        from table (lateral view outer)*
        outer的作用是在UDTF转换列的时候将其中的空也给展示出来，UDTF默认是忽略输出空的，加上outer之后，会将空也输出，显示为null。
14.json_tuple函数
    json_tuple(json_string,k1,k2...)
    解析json的字符串json_string,可指定多个json数据中的key，返回对应的value。如果输入json字符串无效，返回NULL。
    例如：
        select b.name,b.age from table a lateral view json_tuple('{"name":"zhangsan","age":"18"}','name','age') b as name,age;
15.msck repair table table_name
    MSCK REPAIR TABLE TABLE_NAME;
    Hive会检测如果HDFS目录下存在但表的metastore中不存在的partition元信息，更新到metastore中。
    

